{
	"data_loader": {
		"instances_per_epoch": 50000,
		"sampler": {
			"type": "weighted",
			"weights": {
				"nlg": 0.2,
				"sql": 0.8
			}
		},
		"scheduler": {
			"batch_size": 2,
			"type": "homogeneous_roundrobin"
		},
		"shuffle": true,
		"type": "multitask"
	},
	"dataset_reader": {
		"readers": {
			"nlg": {
				"num_tokens_to_mask": 4,
				"maybe_translate_sample_factor": 0.5,
				"source_pretrained_model_name": "facebook/mbart-large-50-many-to-many-mmt",
				"source_token_namespace": "src_tokens",
				"target_token_indexers": {
					"nlg_tokens": {
						"namespace": "nlg_tokens",
						"type": "single_id"
					}
				},
				"type": "seq2seq_pretrain_bitext"
			},
			"sql": {
				"source_pretrained_model_name": "facebook/mbart-large-50-many-to-many-mmt",
				"source_token_namespace": "src_tokens",
				"target_token_indexers": {
					"tgt_tokens": {
						"namespace": "tgt_tokens",
						"type": "single_id"
					}
				},
				"target_tokenizer": {
					"type": "whitespace"
				},
				"type": "seq2seq_pretrain_paired"
			}
		},
		"type": "multitask"
	},
	"model": {
		"decoder_nl": {
			"beam_size": 5,
			"decoder_net": {
				"attention_dropout_prob": 0.1,
				"decoding_dim": 1024,
				"dropout_prob": 0.1,
				"feedforward_hidden_dim": 1024,
				"num_attention_heads": 16,
				"num_layers": 6,
				"residual_dropout_prob": 0.2,
				"target_embedding_dim": 1024,
				"type": "stacked_self_attention"
			},
			"label_smoothing_ratio": 0.1,
			"max_decoding_steps": 30,
			"target_embedder": {
				"embedding_dim": 1024,
				"vocab_namespace": "nlg_tokens"
			},
			"target_namespace": "nlg_tokens",
			"tie_output_embedding": true,
			"type": "auto_regressive_seq_decoder_mod"
		},
		"decoder_sql": {
			"beam_size": 1,
			"decoder_net": {
				"attention_dropout_prob": 0.1,
				"decoding_dim": 1024,
				"dropout_prob": 0.1,
				"feedforward_hidden_dim": 4096,
				"num_attention_heads": 16,
				"num_layers": 6,
				"residual_dropout_prob": 0.2,
				"target_embedding_dim": 1024,
				"type": "stacked_self_attention"
			},
			"label_smoothing_ratio": 0.1,
			"max_decoding_steps": 250,
			"target_embedder": {
				"embedding_dim": 1024,
				"vocab_namespace": "tgt_tokens"
			},
			"target_namespace": "tgt_tokens",
			"tie_output_embedding": false,
			"type": "auto_regressive_seq_decoder_mod"
		},
		"encoder": {
			"feedforward_hidden_dim": 4096,
			"input_dim": 1024,
			"num_attention_heads": 16,
			"num_layers": 1,
			"type": "transformer_encoder",
			"use_positional_encoding": false
		},
		"loss_weights": {
			"dom": 0.33,
			"nlg": 0.1,
			"sql": 1
		},
		"source_text_embedder": {
			"token_embedders": {
				"src_tokens": {
					"model_name": "facebook/mbart-large-50-many-to-many-mmt",
					"sub_module": "encoder",
					"train_parameters": false,
					"type": "pretrained_transformer"
				}
			}
		},
		"type": "seq2seq_multihead_lambda",
		"use_gradient_reversal": true
	},
	"numpy_seed": 1,
	"pytorch_seed": 1,
	"random_seed": 1,
	"train_data_path": {
		"nlg": "data/paracrawl_alllangs_bitext.txt",
		"sql": "data/atis/en.train"
	},
	"trainer": {
		"checkpointer": {
			"keep_most_recent_by_count": 1
		},
		"cuda_device": 0,
		"grad_norm": 1,
		"learning_rate_scheduler": {
			"type": "polynomial_decay",
			"warmup_steps": 4000
		},
		"num_epochs": 100,
		"num_gradient_accumulation_steps": 10,
		"optimizer": {
			"lr": 0.0001,
			"type": "huggingface_adamw",
			"weight_decay": 0.1
		},
		"patience": 30,
		"run_confidence_checks": false,
		"validation_metric": "-loss",
		"callbacks": [
			{
				"batches_per_epoch": 2500,
				"num_epochs": 100,
				"gamma": 20,
				"type": "gradient_lambda_callback"
			}
		]
	},
	"validation_data_loader": {
		"scheduler": {
			"batch_size": 1,
			"type": "homogeneous_roundrobin"
		},
		"shuffle": false,
		"type": "multitask"
	},
	"validation_data_path": {
		"nlg": "data/mkqa_alllangs_bitext_val.txt",
		"sql": "data/atis/en.dev"
	}
}